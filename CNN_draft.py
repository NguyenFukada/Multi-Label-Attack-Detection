# -*- coding: utf-8 -*-
"""Bản sao của Multilabel_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13kFNjmhQ7Tr5b0KavNUQspkStva6Ohbk
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install multilabel-eval-metrics
import keras
import tensorflow as tf
from multilabel_eval_metrics import *
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv1D, MaxPooling1D,Conv2D
from keras.utils import to_categorical
from sklearn.metrics import classification_report
from keras.preprocessing import image
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tqdm import tqdm
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
# %matplotlib inline

train = pd.read_csv('/content/file.csv').iloc[:, :]    # reading the csv file
train.head()      # printing first five rows of the file

X = train.iloc[:, :-2]  # Bỏ hai cột nhãn để có ma trận đặc trưng X
y = train.iloc[:, -2:]# Chọn hai cột nhãn để có ma trận nhãn y
print(X.head())
print("\nMa trận nhãn y:")
print(y.head())

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)
# Initialize StandardScaler
scaler = StandardScaler()

# Fit scaler on training data and transform both training and test data
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
n_inputs, n_outputs = X_train_scaled.shape[1], y_train.shape[1]
X_train_scaled= X_train_scaled.reshape((X_train.shape[0],X_train.shape[1],1))
X_train_scaled = np.array([np.array(val) for val in X_train_scaled])
X_train_scaled  = tf.convert_to_tensor(X_train_scaled, dtype=tf.float32)
print(X_train_scaled.shape);

def get_model(n_inputs, n_outputs):
        model = Sequential()
        model.add(Conv1D(filters=64,kernel_size= (3),activation='relu',input_shape=(n_inputs,1),padding='same'))
        model.add(MaxPooling1D(pool_size=2))
        Dropout(0.5),  # Thêm dropout để tránh overfitting
        model.add(Conv1D(filters=128,kernel_size=(3),activation='relu',padding='same'))
        model.add(MaxPooling1D(pool_size=2))
        Dropout(0.5)
        model.add(Conv1D(filters=256,kernel_size= (3),activation='relu',padding='same'))
        model.add(Flatten())
        model.add(Dense(256, activation='relu'))
        model.add(Dropout(0.5))
        model.add(Dense(128, activation='relu'))
        model.add(Dropout(0.5))
        model.add(Dense(n_outputs, activation='sigmoid'))
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['BinaryAccuracy'])
        return model

y_train

model = get_model(n_inputs, n_outputs)

model.summary()

model.fit(X_train_scaled, y_train, epochs=100, batch_size=64)

# Evaluate the model on the scaled test set
y_pred = model.predict(X_test_scaled)
y_pred_rounded = np.round(y_pred)
y_pred_rounded = y_pred_rounded.astype(np.int32)
# Calculate accuracy
accuracy = np.mean(y_pred_rounded == y_test)
print("Accuracy:", accuracy)

print(classification_report(y_pred_rounded, y_test))

from sklearn.metrics import multilabel_confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Tính toán confusion matrix cho mỗi nhãn
conf_matrices = multilabel_confusion_matrix(y_test, y_pred_rounded)

# Vẽ confusion matrix cho mỗi nhãn
for i, label in enumerate(["ARP Spoofing", "IP Spoofing"]):
    plt.figure(figsize=(5, 4))
    sns.heatmap(conf_matrices[i], annot=True, fmt="d", cmap="Blues")
    plt.title(f"Confusion Matrix for label {label}")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()